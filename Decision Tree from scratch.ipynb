{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1ba8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ab71e",
   "metadata": {},
   "source": [
    "Loading data from local computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d73747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_csv('/Users/computer/OneDrive/Documents/ML github/titanic_train.csv')    #training X and y dataset\n",
    "Test = pd.read_csv('/Users/computer/OneDrive/Documents/ML github/titanic_test.csv')      #testing dataset (X)\n",
    "y_test = pd.read_csv('/Users/computer/OneDrive/Documents/ML github/submission.csv')      #testing dataset (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a22ea58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = [Train, Test]\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fbaaa8",
   "metadata": {},
   "source": [
    "Data Preprocessing from Kaggle Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73fb3fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train['Has_Cabin'] = Train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "Test['Has_Cabin'] = Test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0   \n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "for dataset in full_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(Train['Fare'].median())\n",
    "    \n",
    "for dataset in full_data:\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    # handling exceptions\n",
    "    dataset.loc[np.isnan(dataset['Age']), 'Age'] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    \n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    #title return\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "    \n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')  \n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Sex'] = dataset['Sex'].map({'female' : 0, 'male' : 1}).astype(int)\n",
    "    title_mapping = { 'Mr' : 1, 'Master' :2, 'Mrs' :3, 'Miss' : 4, 'Rare' : 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S' : 0, 'C' : 1, 'Q': 2}).astype(int)\n",
    "\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93e2e916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Survived\n",
      "0           0\n",
      "1           1\n",
      "2           0\n",
      "3           0\n",
      "4           1\n",
      "..        ...\n",
      "413         0\n",
      "414         1\n",
      "415         0\n",
      "416         0\n",
      "417         1\n",
      "\n",
      "[418 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']          #drop excess columns\n",
    "Train = Train.drop(drop_elements, axis = 1)\n",
    "Test = Test.drop(drop_elements, axis = 1)\n",
    "y_test = y_test.drop('PassengerId', axis = 1)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd11cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 1 2 ... 1 1 1]\n",
      " [3 0 2 ... 2 0 3]\n",
      " [2 1 3 ... 1 1 1]\n",
      " ...\n",
      " [3 1 2 ... 1 1 1]\n",
      " [3 1 1 ... 1 1 1]\n",
      " [3 1 1 ... 3 0 2]]\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# y_train = Train['Survived']\n",
    "# X_train = Train.drop(y_train)\n",
    "Train = np.array(Train)                               #making X_train, y_train, X_test, y_test manually\n",
    "y_train = Train[:,0]\n",
    "X_train = Train[:, 1:]\n",
    "X_test = np.array(Test)\n",
    "print(X_test)\n",
    "y_test = np.array(y_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0170b4d8",
   "metadata": {},
   "source": [
    "Decision Tree Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e7ddcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    n = np.bincount(y)\n",
    "    ns = n / len(y)\n",
    "    return -np.sum([ s * np.log2(s) for s in ns if s>0])\n",
    "\n",
    "class Node:\n",
    "    def __init__(\n",
    "        self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        self.f = feature\n",
    "        self.t = threshold\n",
    "        self.l = left\n",
    "        self.r = right\n",
    "        self.value = value\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "\n",
    "class Decision_Tree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=100, n_feats=None):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_feats = n_feats\n",
    "        self.root = None\n",
    "        \n",
    "    def frequent(self, y):\n",
    "#         print(\"y\", y)\n",
    "        if len(y) == 0:\n",
    "            return\n",
    "        c = Counter(y)\n",
    "#         print(\"c\", c)\n",
    "#         if len(c) == 1:\n",
    "#             t = c[0]\n",
    "#         else:\n",
    "        t = c.most_common()[0][0]    \n",
    "        return t\n",
    "        \n",
    "    def build(self, X, y, depth=0):\n",
    "        ns, nf = X.shape\n",
    "        nlab = len(np.unique(y))\n",
    "\n",
    "        # stopping criteria\n",
    "        if (\n",
    "            depth >= self.max_depth\n",
    "            or nlab == 1\n",
    "            or ns < self.min_samples_split):\n",
    "            \n",
    "            leaf_value = self.frequent(y)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        fidx = np.random.choice(nf, self.n_feats, replace=False)\n",
    "\n",
    "        # selecting best split\n",
    "        bf, bt = self.bcriteria(X, y, fidx)\n",
    "\n",
    "        # grow tree\n",
    "        lidxs, ridxs = self._split(X[:, bf], bt)\n",
    "        left = self.build(X[lidxs, :], y[lidxs], depth + 1)\n",
    "        right = self.build(X[ridxs, :], y[ridxs], depth + 1)\n",
    "        return Node(bf, bt, left, right)\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])\n",
    "        self.root = self.build(X, y)\n",
    "    \n",
    "    \n",
    "    def bcriteria(self, X, y, fidxs):\n",
    "        bgain = -1\n",
    "        si, st = None, None\n",
    "        for f in fidxs:\n",
    "            X_c = X[:, f]\n",
    "            ts = np.unique(X_c)\n",
    "            for t in ts:\n",
    "                gain = self.inf_gain(y, X_c, t)\n",
    "\n",
    "                if gain > bgain:\n",
    "                    bgain = gain\n",
    "                    si = f\n",
    "                    st = t\n",
    "\n",
    "        return si, st\n",
    "    \n",
    "    def inf_gain(self, y, X_c, split_t):\n",
    "        # parent entropy\n",
    "        parent_e = entropy(y)\n",
    "\n",
    "        # split\n",
    "        lis, ris = self._split(X_c, split_t)\n",
    "\n",
    "        if len(lis) == 0 or len(ris) == 0:\n",
    "            return 0\n",
    "\n",
    "        n = len(y)\n",
    "        nl, nr = len(lis), len(ris)\n",
    "        el, er = entropy(y[lis]), entropy(y[ris])\n",
    "        child_e = (nl / n) * el + (nr / n) * er\n",
    "\n",
    "        # information gain calculation\n",
    "        ig = parent_e - child_e\n",
    "        return ig\n",
    "\n",
    "    def _split(self, X_column, split_t):\n",
    "        l_idxs = np.argwhere(X_column <= split_t).flatten()\n",
    "        r_idxs = np.argwhere(X_column > split_t).flatten()\n",
    "        return l_idxs, r_idxs\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array([self.traverse_t(x, self.root) for x in X])\n",
    " \n",
    "    def traverse_t(self, x, node):\n",
    "        if node == None:\n",
    "            return 0\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "#         print(\"X\", x)\n",
    "#         print(node.value, node)\n",
    "#         print(node.f, node.t)\n",
    "        \n",
    "        z = node.t\n",
    "#         print(\"node f\", node.f)\n",
    "#         print(\"X\", x)\n",
    "        if node.f and node.t != None:\n",
    "            if x[node.f] <= node.t:\n",
    "                return self.traverse_t(x, node.l)\n",
    "        return self.traverse_t(x, node.r)\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd06a4",
   "metadata": {},
   "source": [
    "Training and Testing our Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ded26165",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Decision_Tree()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2616b945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418 418\n",
      "accuracy [65.78947368]\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    print(len(y_true), len(y_pred))\n",
    "#     print(y_true, \"y_pred\", y_pred)\n",
    "    acc = (sum(a == b for a,b in zip(y_true, y_pred))) / (len(y_true))\n",
    "    return acc*100\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy(y_test, y_pred)\n",
    "print(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60509fe",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "090ceca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFfrequent(y):\n",
    "    z = []\n",
    "    for i in range(len(y)):\n",
    "        if type(i) == list:\n",
    "            i=tuple(i)\n",
    "        z = np.append(z,i)\n",
    "    counter = Counter(z)\n",
    "    most_common = counter.most_common(1)[0][0]\n",
    "    return most_common\n",
    "\n",
    "class RandomForest:    \n",
    "    def __init__(self, nt = 3, min_samples_split = 2, max_depth = 50, n_feats = None):\n",
    "        self.nt = nt\n",
    "        print(self.nt)\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_feats = n_feats\n",
    "        self.arrTree = []\n",
    "     \n",
    "    def fit(self, X,y):\n",
    "        self.arrTree = []\n",
    "        for _ in range (self.nt):\n",
    "            t = Decision_Tree(min_samples_split = self.min_samples_split,\n",
    "                             max_depth = self.max_depth, n_feats = self.n_feats)\n",
    "            nsamp = X.shape[0]\n",
    "            idx = np.random.choice(nsamp, size = nsamp, replace = True)\n",
    "            t.fit(X[idx], y[idx])\n",
    "            self.arrTree.append(t)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        t_preds = np.array([t.predict(X) for t in self.arrTree])\n",
    "        t_preds = np.swapaxes(t_preds, 0,1)\n",
    "        print(\"tree_preds\", t_preds)\n",
    "        y_pred = [RFfrequent(pred) for pred in t_preds]\n",
    "        return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f1df34",
   "metadata": {},
   "source": [
    "Training and testing our random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75e14673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForest(nt = 100)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6e1e543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_preds [[0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 1 ... 1 1 0]]\n",
      "418 418\n",
      "accuracy [59.80861244]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "# print(\"y\", y_pred) \n",
    "# print(\"y_t\", y_test)\n",
    "acc = accuracy(y_test, y_pred)\n",
    "print(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bc5b4f",
   "metadata": {},
   "source": [
    "Code in Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e605216",
   "metadata": {},
   "source": [
    "# ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1069966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Find:\n",
    "    def __init__(self):\n",
    "        self.sign = 1\n",
    "        self.feature_idx = None\n",
    "        self.threshold = None\n",
    "        self.alpha = None\n",
    "\n",
    "    def calculate(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        X_column = X[:, self.feature_idx]\n",
    "        predictions = np.ones(n_samples)\n",
    "        if self.sign == 1:\n",
    "            predictions[X_column < self.threshold] = -1\n",
    "        else:\n",
    "            predictions[X_column > self.threshold] = -1\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "class Adaboost:\n",
    "    def __init__(self, n_clf=5, lr = 0.01):\n",
    "        self.n_clf = n_clf\n",
    "        self.lr = 1e-10\n",
    "        self.clfs = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # weights initialization to 1/N\n",
    "        w = np.full(n_samples, (1 / n_samples))\n",
    "\n",
    "        self.clfs = []\n",
    "\n",
    "\n",
    "        for _ in range(self.n_clf):\n",
    "            clf = Find()\n",
    "            min_error = float(\"inf\")\n",
    "\n",
    "            #finding best threshold and feature\n",
    "            for feature_i in range(n_features):\n",
    "                X_column = X[:, feature_i]\n",
    "                thresholds = np.unique(X_column)\n",
    "\n",
    "                for threshold in thresholds:\n",
    "                    s = 1\n",
    "                    predictions = np.ones(n_samples)\n",
    "                    predictions[X_column < threshold] = -1\n",
    "\n",
    "                    # Error \n",
    "                    mis = w[y != predictions]\n",
    "                    error = sum(mis)\n",
    "\n",
    "                    if error > 0.5:\n",
    "                        error = 1 - error\n",
    "                        s = -1\n",
    "\n",
    "                    # best configuration\n",
    "                    if error < min_error:\n",
    "                        clf.sign = s\n",
    "                        clf.threshold = threshold\n",
    "                        clf.feature_idx = feature_i\n",
    "                        min_error = error\n",
    "\n",
    "            clf.alp = 0.5 * np.log((1.0 - min_error + self.lr) / (min_error + self.lr))\n",
    "\n",
    "            # update weights\n",
    "            predictions = clf.calculate(X)\n",
    "\n",
    "            w *= np.exp(-clf.alp * y * predictions)\n",
    "            # Normalization\n",
    "            w /= np.sum(w)\n",
    "\n",
    "            # Saving classifier\n",
    "            self.clfs.append(clf)\n",
    "\n",
    "    def predict(self, X):\n",
    "        clf_preds = [clf.alp * clf.calculate(X) for clf in self.clfs]\n",
    "        y_pred = np.sum(clf_preds, axis=0)\n",
    "        y_pred = np.sign(y_pred)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d878fbc2",
   "metadata": {},
   "source": [
    "Training and Testing Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d7a5f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Adaboost(n_clf = 5, lr = 1e-10)\n",
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f7fdeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78359430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418 418\n",
      "Accuracy: [40.19138756]\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d53b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda02e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f43ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d7b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cse6363] *",
   "language": "python",
   "name": "conda-env-cse6363-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
